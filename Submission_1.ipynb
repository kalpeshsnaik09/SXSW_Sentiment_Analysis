{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6441945970995222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.90,\n",
    "    ngram_range=(1,3), \n",
    "    min_df=2, \n",
    "    max_features=1500, \n",
    "    stop_words='english'\n",
    "    )\n",
    "rf=RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    criterion='gini'\n",
    "    )\n",
    "\n",
    "data=pd.read_csv('Data/clean_data.csv')\n",
    "\n",
    "tfidf_data=tfidf_vectorizer.fit_transform(data['cleanText'].apply(lambda x: np.str_(x)))\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(tfidf_data,data['sentiment'],test_size=0.3,random_state=0)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fun for cleaning test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Create a function to clean tweets\n",
    "def cleanText(text):\n",
    "    text=str(text)  #Coverts Text to String\n",
    "    text=re.sub(r'@[A-Za-z0-9]+','',text)  #Removing @Mentions\n",
    "    text = re.sub(r'#[\\w]*sxsw[\\w]*', ' ', text,flags=re.I)  #Removing sxsw hashtag\n",
    "    text=re.sub(r'#','',text)  #Removing # Symbols\n",
    "    text=re.sub(r'RT[\\s]+','',text)  #Removing ReTweets\n",
    "    text=re.sub(r'https?:\\/\\/\\s+','',text)  #Removing the hyperlinks\n",
    "    text=re.sub(r'bit.ly[/\\.\\w]+','',text)  #Removing the shortlinks \n",
    "    text=text.replace(r'{html}',\"\") \n",
    "    cleanr = re.compile(r'<.*?>')\n",
    "    text = re.sub(cleanr, '', text)\n",
    "    text = re.sub(r'[0-9]+', '', text)  #Removing Numbers\n",
    "    text = re.sub(r'[^A-Za-z]+', ' ', text)  #Removing all spacial character\n",
    "    text = text.lower()  #Coverts Text To Lower Case\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text) \n",
    "    filtered_words = [w for w in tokens if w not in stopwords.words('english')]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "    return \" \".join(lemma_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Data/test.csv')\n",
    "data['cleanText']=data['tweet'].map(lambda s:cleanText(s))\n",
    "data_tfidf=tfidf_vectorizer.transform(data['cleanText'])\n",
    "y_pred=rf.predict(data_tfidf)\n",
    "output=pd.concat([data['tweet_id'],pd.DataFrame(y_pred,columns=['sentiment'])],axis=1)\n",
    "output.to_csv('Data/submission_file.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
